
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>nltk.test.unit.test_tokenize &#8212; NLTK 3.6.2 documentation</title>
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/agogo.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
  </head><body>
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="../../../../index.html">NLTK 3.6.2 documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for nltk.test.unit.test_tokenize</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Unit tests for nltk.tokenize.</span>
<span class="sd">See also nltk/test/tokenize.doctest</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pytest</span>

<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">punkt</span><span class="p">,</span>
    <span class="n">word_tokenize</span><span class="p">,</span>
    <span class="n">TweetTokenizer</span><span class="p">,</span>
    <span class="n">StanfordSegmenter</span><span class="p">,</span>
    <span class="n">TreebankWordTokenizer</span><span class="p">,</span>
    <span class="n">SyllableTokenizer</span><span class="p">,</span>
    <span class="n">LegalitySyllableTokenizer</span><span class="p">,</span>
<span class="p">)</span>

<div class="viewcode-block" id="setup_module"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.setup_module">[docs]</a><span class="k">def</span> <span class="nf">setup_module</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">pytest</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">seg</span> <span class="o">=</span> <span class="n">StanfordSegmenter</span><span class="p">()</span>
        <span class="n">seg</span><span class="o">.</span><span class="n">default_config</span><span class="p">(</span><span class="s2">&quot;ar&quot;</span><span class="p">)</span>
        <span class="n">seg</span><span class="o">.</span><span class="n">default_config</span><span class="p">(</span><span class="s2">&quot;zh&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">LookupError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span>
            <span class="s2">&quot;Tests for nltk.tokenize.stanford_segmenter skipped: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">StanfordTokenizer</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">LookupError</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span>
            <span class="s2">&quot;Tests for nltk.tokenize.stanford are skipped because the stanford postagger jar doesn&#39;t exist&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TestTokenize"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize">[docs]</a><span class="k">class</span> <span class="nc">TestTokenize</span><span class="p">:</span>
<div class="viewcode-block" id="TestTokenize.test_tweet_tokenizer"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_tweet_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">test_tweet_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test TweetTokenizer using words with special and accented characters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">s9</span> <span class="o">=</span> <span class="s2">&quot;@myke: Let&#39;s test these words: resumé España München français&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s9</span><span class="p">)</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;:&#39;</span><span class="p">,</span>
            <span class="s2">&quot;Let&#39;s&quot;</span><span class="p">,</span>
            <span class="s1">&#39;test&#39;</span><span class="p">,</span>
            <span class="s1">&#39;these&#39;</span><span class="p">,</span>
            <span class="s1">&#39;words&#39;</span><span class="p">,</span>
            <span class="s1">&#39;:&#39;</span><span class="p">,</span>
            <span class="s1">&#39;resumé&#39;</span><span class="p">,</span>
            <span class="s1">&#39;España&#39;</span><span class="p">,</span>
            <span class="s1">&#39;München&#39;</span><span class="p">,</span>
            <span class="s1">&#39;français&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">assert</span> <span class="n">tokens</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_sonority_sequencing_syllable_tokenizer"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_sonority_sequencing_syllable_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">test_sonority_sequencing_syllable_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test SyllableTokenizer tokenizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SyllableTokenizer</span><span class="p">()</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;justification&#39;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">tokens</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;jus&#39;</span><span class="p">,</span> <span class="s1">&#39;ti&#39;</span><span class="p">,</span> <span class="s1">&#39;fi&#39;</span><span class="p">,</span> <span class="s1">&#39;ca&#39;</span><span class="p">,</span> <span class="s1">&#39;tion&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="TestTokenize.test_legality_principle_syllable_tokenizer"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_legality_principle_syllable_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">test_legality_principle_syllable_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test LegalitySyllableTokenizer tokenizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">words</span>
        <span class="n">test_word</span> <span class="o">=</span> <span class="s2">&quot;wonderful&quot;</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">LegalitySyllableTokenizer</span><span class="p">(</span><span class="n">words</span><span class="o">.</span><span class="n">words</span><span class="p">())</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_word</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">tokens</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;won&#39;</span><span class="p">,</span> <span class="s1">&#39;der&#39;</span><span class="p">,</span> <span class="s1">&#39;ful&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="TestTokenize.test_stanford_segmenter_arabic"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_stanford_segmenter_arabic">[docs]</a>    <span class="k">def</span> <span class="nf">test_stanford_segmenter_arabic</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test the Stanford Word Segmenter for Arabic (default config)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">seg</span> <span class="o">=</span> <span class="n">StanfordSegmenter</span><span class="p">()</span>
            <span class="n">seg</span><span class="o">.</span><span class="n">default_config</span><span class="p">(</span><span class="s1">&#39;ar&#39;</span><span class="p">)</span>
            <span class="n">sent</span> <span class="o">=</span> <span class="sa">u</span><span class="s1">&#39;يبحث علم الحاسوب استخدام الحوسبة بجميع اشكالها لحل المشكلات&#39;</span>
            <span class="n">segmented_sent</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">segment</span><span class="p">(</span><span class="n">sent</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="k">assert</span> <span class="n">segmented_sent</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span>
                <span class="s1">&#39;يبحث&#39;</span><span class="p">,</span>
                <span class="s1">&#39;علم&#39;</span><span class="p">,</span>
                <span class="s1">&#39;الحاسوب&#39;</span><span class="p">,</span>
                <span class="s1">&#39;استخدام&#39;</span><span class="p">,</span>
                <span class="s1">&#39;الحوسبة&#39;</span><span class="p">,</span>
                <span class="s1">&#39;ب&#39;</span><span class="p">,</span>
                <span class="s1">&#39;جميع&#39;</span><span class="p">,</span>
                <span class="s1">&#39;اشكال&#39;</span><span class="p">,</span>
                <span class="s1">&#39;ها&#39;</span><span class="p">,</span>
                <span class="s1">&#39;ل&#39;</span><span class="p">,</span>
                <span class="s1">&#39;حل&#39;</span><span class="p">,</span>
                <span class="s1">&#39;المشكلات&#39;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="k">except</span> <span class="ne">LookupError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span></div>

<div class="viewcode-block" id="TestTokenize.test_stanford_segmenter_chinese"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_stanford_segmenter_chinese">[docs]</a>    <span class="k">def</span> <span class="nf">test_stanford_segmenter_chinese</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test the Stanford Word Segmenter for Chinese (default config)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">seg</span> <span class="o">=</span> <span class="n">StanfordSegmenter</span><span class="p">()</span>
            <span class="n">seg</span><span class="o">.</span><span class="n">default_config</span><span class="p">(</span><span class="s1">&#39;zh&#39;</span><span class="p">)</span>
            <span class="n">sent</span> <span class="o">=</span> <span class="sa">u</span><span class="s2">&quot;这是斯坦福中文分词器测试&quot;</span>
            <span class="n">segmented_sent</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">segment</span><span class="p">(</span><span class="n">sent</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="k">assert</span> <span class="n">segmented_sent</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;这&#39;</span><span class="p">,</span> <span class="s1">&#39;是&#39;</span><span class="p">,</span> <span class="s1">&#39;斯坦福&#39;</span><span class="p">,</span> <span class="s1">&#39;中文&#39;</span><span class="p">,</span> <span class="s1">&#39;分词器&#39;</span><span class="p">,</span> <span class="s1">&#39;测试&#39;</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">LookupError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span></div>

<div class="viewcode-block" id="TestTokenize.test_phone_tokenizer"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_phone_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">test_phone_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test a string that resembles a phone number but contains a newline</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Should be recognized as a phone number, albeit one with multiple spaces</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">()</span>
        <span class="n">test1</span> <span class="o">=</span> <span class="s2">&quot;(393)  928 -3010&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;(393)  928 -3010&#39;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test1</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Due to newline, first three elements aren&#39;t part of a phone number;</span>
        <span class="c1"># fourth is</span>
        <span class="n">test2</span> <span class="o">=</span> <span class="s2">&quot;(393)</span><span class="se">\n</span><span class="s2">928 -3010&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;393&#39;</span><span class="p">,</span> <span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s2">&quot;928 -3010&quot;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test2</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_pad_asterisk"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_pad_asterisk">[docs]</a>    <span class="k">def</span> <span class="nf">test_pad_asterisk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test padding of asterisk for word tokenization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is a, *weird sentence with *asterisks in it.&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;This&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;weird&#39;</span><span class="p">,</span> <span class="s1">&#39;sentence&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;with&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;asterisks&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_pad_dotdot"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_pad_dotdot">[docs]</a>    <span class="k">def</span> <span class="nf">test_pad_dotdot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test padding of dotdot* for word tokenization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Why did dotdot.. not get tokenized but dotdotdot... did? How about manydots.....&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Why&#39;</span><span class="p">,</span> <span class="s1">&#39;did&#39;</span><span class="p">,</span> <span class="s1">&#39;dotdot&#39;</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;not&#39;</span><span class="p">,</span> <span class="s1">&#39;get&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;tokenized&#39;</span><span class="p">,</span> <span class="s1">&#39;but&#39;</span><span class="p">,</span> <span class="s1">&#39;dotdotdot&#39;</span><span class="p">,</span> <span class="s1">&#39;...&#39;</span><span class="p">,</span> <span class="s1">&#39;did&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;How&#39;</span><span class="p">,</span> <span class="s1">&#39;about&#39;</span><span class="p">,</span> <span class="s1">&#39;manydots&#39;</span><span class="p">,</span> <span class="s1">&#39;.....&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_remove_handle"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_remove_handle">[docs]</a>    <span class="k">def</span> <span class="nf">test_remove_handle</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test remove_handle() from casual.py with specially crafted edge cases</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Simple example. Handles with just numbers should be allowed</span>
        <span class="n">test1</span> <span class="o">=</span> <span class="s2">&quot;@twitter hello @twi_tter_. hi @12345 @123news&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;hi&#39;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test1</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Handles are allowed to follow any of the following characters</span>
        <span class="n">test2</span> <span class="o">=</span> <span class="s2">&quot;@n`@n~@n(@n)@n-@n=@n+@n</span><span class="se">\\</span><span class="s2">@n|@n[@n]@n{@n}@n;@n:@n&#39;@n</span><span class="se">\&quot;</span><span class="s2">@n/@n?@n.@n,@n&lt;@n&gt;@n @n</span><span class="se">\n</span><span class="s2">@n ñ@n.ü@n.ç@n.&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;`&#39;</span><span class="p">,</span>
            <span class="s1">&#39;~&#39;</span><span class="p">,</span>
            <span class="s1">&#39;(&#39;</span><span class="p">,</span>
            <span class="s1">&#39;)&#39;</span><span class="p">,</span>
            <span class="s1">&#39;-&#39;</span><span class="p">,</span>
            <span class="s1">&#39;=&#39;</span><span class="p">,</span>
            <span class="s1">&#39;+&#39;</span><span class="p">,</span>
            <span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span>
            <span class="s1">&#39;|&#39;</span><span class="p">,</span>
            <span class="s1">&#39;[&#39;</span><span class="p">,</span>
            <span class="s1">&#39;]&#39;</span><span class="p">,</span>
            <span class="s1">&#39;{&#39;</span><span class="p">,</span>
            <span class="s1">&#39;}&#39;</span><span class="p">,</span>
            <span class="s1">&#39;;&#39;</span><span class="p">,</span>
            <span class="s1">&#39;:&#39;</span><span class="p">,</span>
            <span class="s2">&quot;&#39;&quot;</span><span class="p">,</span>
            <span class="s1">&#39;&quot;&#39;</span><span class="p">,</span>
            <span class="s1">&#39;/&#39;</span><span class="p">,</span>
            <span class="s1">&#39;?&#39;</span><span class="p">,</span>
            <span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;,&#39;</span><span class="p">,</span>
            <span class="s1">&#39;&lt;&#39;</span><span class="p">,</span>
            <span class="s1">&#39;&gt;&#39;</span><span class="p">,</span>
            <span class="s1">&#39;ñ&#39;</span><span class="p">,</span>
            <span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;ü&#39;</span><span class="p">,</span>
            <span class="s1">&#39;.&#39;</span><span class="p">,</span>
            <span class="s1">&#39;ç&#39;</span><span class="p">,</span>
            <span class="s1">&#39;.&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test2</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Handles are NOT allowed to follow any of the following characters</span>
        <span class="n">test3</span> <span class="o">=</span> <span class="s2">&quot;a@n j@n z@n A@n L@n Z@n 1@n 4@n 7@n 9@n 0@n _@n !@n @@n #@n $@n %@n &amp;@n *@n&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;a&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;j&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;z&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;A&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;L&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Z&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;1&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;4&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;7&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;9&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;0&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;_&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;!&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;#&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;$&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;%&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;&amp;&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;*&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test3</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Handles are allowed to precede the following characters</span>
        <span class="n">test4</span> <span class="o">=</span> <span class="s2">&quot;@n!a @n#a @n$a @n</span><span class="si">%a</span><span class="s2"> @n&amp;a @n*a&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;#&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;$&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;&amp;&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test4</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Tests interactions with special symbols and multiple @</span>
        <span class="n">test5</span> <span class="o">=</span> <span class="s2">&quot;@n!@n @n#@n @n$@n @n%@n @n&amp;@n @n*@n @n@n @@n @n@@n @n_@n @n7@n @nj@n&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;!&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;#&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;$&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;%&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;&amp;&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;*&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n_&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n7&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@nj&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@n&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test5</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Tests that handles can have a max length of 20</span>
        <span class="n">test6</span> <span class="o">=</span> <span class="s2">&quot;@abcdefghijklmnopqrstuvwxyz @abcdefghijklmnopqrst1234 @abcdefghijklmnopqrst_ @abcdefghijklmnopqrstendofhandle&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;uvwxyz&#39;</span><span class="p">,</span> <span class="s1">&#39;1234&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="s1">&#39;endofhandle&#39;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test6</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Edge case where an @ comes directly after a long handle</span>
        <span class="n">test7</span> <span class="o">=</span> <span class="s2">&quot;@abcdefghijklmnopqrstu@abcde @abcdefghijklmnopqrst@abcde @abcdefghijklmnopqrst_@abcde @abcdefghijklmnopqrst5@abcde&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;u&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@abcde&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@abcdefghijklmnopqrst&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@abcde&#39;</span><span class="p">,</span>
            <span class="s1">&#39;_&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@abcde&#39;</span><span class="p">,</span>
            <span class="s1">&#39;5&#39;</span><span class="p">,</span>
            <span class="s1">&#39;@abcde&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test7</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_treebank_span_tokenizer"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_treebank_span_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">test_treebank_span_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test TreebankWordTokenizer.span_tokenize function</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TreebankWordTokenizer</span><span class="p">()</span>

        <span class="c1"># Test case in the docstring</span>
        <span class="n">test1</span> <span class="o">=</span> <span class="s2">&quot;Good muffins cost $3.88</span><span class="se">\n</span><span class="s2">in New (York).  Please (buy) me</span><span class="se">\n</span><span class="s2">two of them.</span><span class="se">\n</span><span class="s2">(Thanks).&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">23</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">26</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">36</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">37</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">37</span><span class="p">,</span> <span class="mi">38</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">46</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">47</span><span class="p">,</span> <span class="mi">48</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">48</span><span class="p">,</span> <span class="mi">51</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">52</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">53</span><span class="p">,</span> <span class="mi">55</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">56</span><span class="p">,</span> <span class="mi">59</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">62</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">63</span><span class="p">,</span> <span class="mi">68</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">69</span><span class="p">,</span> <span class="mi">70</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">76</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">76</span><span class="p">,</span> <span class="mi">77</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">77</span><span class="p">,</span> <span class="mi">78</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">span_tokenize</span><span class="p">(</span><span class="n">test1</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Test case with double quotation</span>
        <span class="n">test2</span> <span class="o">=</span> <span class="s2">&quot;The DUP is similar to the </span><span class="se">\&quot;</span><span class="s2">religious right</span><span class="se">\&quot;</span><span class="s2"> in the United States and takes a hardline stance on social issues&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">26</span><span class="p">,</span> <span class="mi">27</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">36</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">37</span><span class="p">,</span> <span class="mi">42</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">43</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">44</span><span class="p">,</span> <span class="mi">46</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">47</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">57</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">58</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">68</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">69</span><span class="p">,</span> <span class="mi">74</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">76</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">77</span><span class="p">,</span> <span class="mi">85</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">86</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">93</span><span class="p">,</span> <span class="mi">95</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">102</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">103</span><span class="p">,</span> <span class="mi">109</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">span_tokenize</span><span class="p">(</span><span class="n">test2</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="c1"># Test case with double qoutation as well as converted quotations</span>
        <span class="n">test3</span> <span class="o">=</span> <span class="s2">&quot;The DUP is similar to the </span><span class="se">\&quot;</span><span class="s2">religious right</span><span class="se">\&quot;</span><span class="s2"> in the United States and takes a ``hardline&#39;&#39; stance on social issues&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">26</span><span class="p">,</span> <span class="mi">27</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">36</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">37</span><span class="p">,</span> <span class="mi">42</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="mi">43</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">44</span><span class="p">,</span> <span class="mi">46</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">47</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">57</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">58</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">68</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">69</span><span class="p">,</span> <span class="mi">74</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">76</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">77</span><span class="p">,</span> <span class="mi">79</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">79</span><span class="p">,</span> <span class="mi">87</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">87</span><span class="p">,</span> <span class="mi">89</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">90</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">97</span><span class="p">,</span> <span class="mi">99</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">106</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">107</span><span class="p">,</span> <span class="mi">113</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">span_tokenize</span><span class="p">(</span><span class="n">test3</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">result</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_word_tokenize"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_word_tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">test_word_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test word_tokenize function</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;The &#39;v&#39;, I&#39;ve been fooled but I&#39;ll seek revenge.&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;The&#39;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s2">&quot;&#39;ve&quot;</span><span class="p">,</span> <span class="s1">&#39;been&#39;</span><span class="p">,</span> <span class="s1">&#39;fooled&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;but&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s2">&quot;&#39;ll&quot;</span><span class="p">,</span> <span class="s1">&#39;seek&#39;</span><span class="p">,</span> <span class="s1">&#39;revenge&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span>

        <span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;&#39;v&#39; &#39;re&#39;&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;re&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_punkt_pair_iter"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_punkt_pair_iter">[docs]</a>    <span class="k">def</span> <span class="nf">test_punkt_pair_iter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;12&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]),</span>
            <span class="p">(</span><span class="s1">&#39;123&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]),</span>
            <span class="p">(</span><span class="s1">&#39;1234&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;4&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]),</span>
        <span class="p">]</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
            <span class="n">actual_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">punkt</span><span class="o">.</span><span class="n">_pair_iter</span><span class="p">(</span><span class="n">test_input</span><span class="p">)]</span>

            <span class="k">assert</span> <span class="n">actual_output</span> <span class="o">==</span> <span class="n">expected_output</span></div>

<div class="viewcode-block" id="TestTokenize.test_punkt_pair_iter_handles_stop_iteration_exception"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_punkt_pair_iter_handles_stop_iteration_exception">[docs]</a>    <span class="k">def</span> <span class="nf">test_punkt_pair_iter_handles_stop_iteration_exception</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># test input to trigger StopIteration from next()</span>
        <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">([])</span>
        <span class="c1"># call method under test and produce a generator</span>
        <span class="n">gen</span> <span class="o">=</span> <span class="n">punkt</span><span class="o">.</span><span class="n">_pair_iter</span><span class="p">(</span><span class="n">it</span><span class="p">)</span>
        <span class="c1"># unpack generator, ensure that no error is raised</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span></div>

<div class="viewcode-block" id="TestTokenize.test_punkt_tokenize_words_handles_stop_iteration_exception"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_punkt_tokenize_words_handles_stop_iteration_exception">[docs]</a>    <span class="k">def</span> <span class="nf">test_punkt_tokenize_words_handles_stop_iteration_exception</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">punkt</span><span class="o">.</span><span class="n">PunktBaseClass</span><span class="p">()</span>

        <span class="k">class</span> <span class="nc">TestPunktTokenizeWordsMock</span><span class="p">:</span>
            <span class="k">def</span> <span class="nf">word_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
                <span class="k">return</span> <span class="nb">iter</span><span class="p">([])</span>

        <span class="n">obj</span><span class="o">.</span><span class="n">_lang_vars</span> <span class="o">=</span> <span class="n">TestPunktTokenizeWordsMock</span><span class="p">()</span>
        <span class="c1"># unpack generator, ensure that no error is raised</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">_tokenize_words</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">))</span></div>

<div class="viewcode-block" id="TestTokenize.test_punkt_tokenize_custom_lang_vars"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_punkt_tokenize_custom_lang_vars">[docs]</a>    <span class="k">def</span> <span class="nf">test_punkt_tokenize_custom_lang_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="c1"># Create LangVars including a full stop end character as used in Bengali</span>
        <span class="k">class</span> <span class="nc">BengaliLanguageVars</span><span class="p">(</span><span class="n">punkt</span><span class="o">.</span><span class="n">PunktLanguageVars</span><span class="p">):</span>
            <span class="n">sent_end_chars</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\u0964</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">punkt</span><span class="o">.</span><span class="n">PunktSentenceTokenizer</span><span class="p">(</span><span class="n">lang_vars</span> <span class="o">=</span> <span class="n">BengaliLanguageVars</span><span class="p">())</span>

        <span class="c1"># We now expect these sentences to be split up into the individual sentences</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="sa">u</span><span class="s2">&quot;উপরাষ্ট্রপতি শ্রী এম ভেঙ্কাইয়া নাইডু সোমবার আই আই টি দিল্লির হীরক জয়ন্তী উদযাপনের উদ্বোধন করেছেন। অনলাইনের মাধ্যমে এই অনুষ্ঠানে কেন্দ্রীয় মানব সম্পদ উন্নয়নমন্ত্রী শ্রী রমেশ পোখরিয়াল ‘নিশাঙ্ক’  উপস্থিত ছিলেন। এই উপলক্ষ্যে উপরাষ্ট্রপতি হীরকজয়ন্তীর লোগো এবং ২০৩০-এর জন্য প্রতিষ্ঠানের লক্ষ্য ও পরিকল্পনার নথি প্রকাশ করেছেন।&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;উপরাষ্ট্রপতি শ্রী এম ভেঙ্কাইয়া নাইডু সোমবার আই আই টি দিল্লির হীরক জয়ন্তী উদযাপনের উদ্বোধন করেছেন।&quot;</span><span class="p">,</span> <span class="s2">&quot;অনলাইনের মাধ্যমে এই অনুষ্ঠানে কেন্দ্রীয় মানব সম্পদ উন্নয়নমন্ত্রী শ্রী রমেশ পোখরিয়াল ‘নিশাঙ্ক’  উপস্থিত ছিলেন।&quot;</span><span class="p">,</span> <span class="s2">&quot;এই উপলক্ষ্যে উপরাষ্ট্রপতি হীরকজয়ন্তীর লোগো এবং ২০৩০-এর জন্য প্রতিষ্ঠানের লক্ষ্য ও পরিকল্পনার নথি প্রকাশ করেছেন।&quot;</span><span class="p">]</span>
        
        <span class="k">assert</span> <span class="n">obj</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span></div>

<div class="viewcode-block" id="TestTokenize.test_punkt_tokenize_no_custom_lang_vars"><a class="viewcode-back" href="../../../../api/nltk.test.unit.html#nltk.test.unit.test_tokenize.TestTokenize.test_punkt_tokenize_no_custom_lang_vars">[docs]</a>    <span class="k">def</span> <span class="nf">test_punkt_tokenize_no_custom_lang_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">obj</span> <span class="o">=</span> <span class="n">punkt</span><span class="o">.</span><span class="n">PunktSentenceTokenizer</span><span class="p">()</span>

        <span class="c1"># We expect these sentences to not be split properly, as the Bengali full stop &#39;।&#39; is not included in the default language vars</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="sa">u</span><span class="s2">&quot;উপরাষ্ট্রপতি শ্রী এম ভেঙ্কাইয়া নাইডু সোমবার আই আই টি দিল্লির হীরক জয়ন্তী উদযাপনের উদ্বোধন করেছেন। অনলাইনের মাধ্যমে এই অনুষ্ঠানে কেন্দ্রীয় মানব সম্পদ উন্নয়নমন্ত্রী শ্রী রমেশ পোখরিয়াল ‘নিশাঙ্ক’  উপস্থিত ছিলেন। এই উপলক্ষ্যে উপরাষ্ট্রপতি হীরকজয়ন্তীর লোগো এবং ২০৩০-এর জন্য প্রতিষ্ঠানের লক্ষ্য ও পরিকল্পনার নথি প্রকাশ করেছেন।&quot;</span>
        <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;উপরাষ্ট্রপতি শ্রী এম ভেঙ্কাইয়া নাইডু সোমবার আই আই টি দিল্লির হীরক জয়ন্তী উদযাপনের উদ্বোধন করেছেন। অনলাইনের মাধ্যমে এই অনুষ্ঠানে কেন্দ্রীয় মানব সম্পদ উন্নয়নমন্ত্রী শ্রী রমেশ পোখরিয়াল ‘নিশাঙ্ক’  উপস্থিত ছিলেন। এই উপলক্ষ্যে উপরাষ্ট্রপতি হীরকজয়ন্তীর লোগো এবং ২০৩০-এর জন্য প্রতিষ্ঠানের লক্ষ্য ও পরিকল্পনার নথি প্রকাশ করেছেন।&quot;</span><span class="p">]</span>
        
        <span class="k">assert</span> <span class="n">obj</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span></div></div>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          
          <h3>Table of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../news.html">NLTK News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">Installing NLTK Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contribute.html">Contribute to NLTK</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/nltk.html">API</a></li>
<li class="toctree-l1"><a class="reference external" href="http://www.nltk.org/howto">HOWTO</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="../../../../search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
            </form>
          </div>

        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="../../../../py-modindex.html" title="Python Module Index"
              >modules</a> |
            <a href="../../../../genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, NLTK Project.
      Last updated on Apr 20, 2021.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.5.2.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>